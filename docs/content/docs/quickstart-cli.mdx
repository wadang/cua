---
title: Quickstart (CLI)
description: Get started with the Cua Agent CLI in 4 steps
icon: Rocket
---

import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

Get up and running with the Cua Agent CLI in 4 simple steps.

<Steps>
<Step>

## Introduction

Cua combines Computer (interface) + Agent (AI) for automating desktop apps. The Agent CLI provides a clean terminal interface to control your remote computer using natural language commands.

</Step>

<Step>

## Set Up Your Computer Environment

Choose how you want to run your Cua computer. **Cloud Sandbox is recommended** for the easiest setup:

<Tabs items={['â˜ï¸ Cloud Sandbox (Recommended)', 'Linux on Docker', 'Windows Sandbox', 'macOS VM']}>
  <Tab value="â˜ï¸ Cloud Sandbox (Recommended)">

    **Easiest & safest way to get started - works on any host OS**

    1. Go to [trycua.com/signin](https://www.trycua.com/signin)
    2. Navigate to **Dashboard > Containers > Create Instance**
    3. Create a **Medium, Ubuntu 22** container
    4. Note your container name and API key

    Your cloud container will be automatically configured and ready to use.

  </Tab>
  <Tab value="Linux on Docker">

    **Run Linux desktop locally on macOS, Windows, or Linux hosts**

    1. Install Docker Desktop or Docker Engine

    2. Pull the CUA XFCE container (lightweight desktop)

    ```bash
    docker pull --platform=linux/amd64 trycua/cua-xfce:latest
    ```

    Or use KASM for a full-featured desktop:

    ```bash
    docker pull --platform=linux/amd64 trycua/cua-ubuntu:latest
    ```

  </Tab>
  <Tab value="Windows Sandbox">

    **Windows hosts only - requires Windows 10 Pro/Enterprise or Windows 11**

    1. Enable Windows Sandbox
    2. Install pywinsandbox dependency

    ```bash
    pip install -U git+git://github.com/karkason/pywinsandbox.git
    ```

    3. Windows Sandbox will be automatically configured when you run the CLI

  </Tab>
  <Tab value="macOS VM">

    **macOS hosts only - requires Lume CLI**

    1. Install lume cli

    ```bash
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)"
    ```

    2. Start a local Cua macOS VM

    ```bash
    lume run macos-sequoia-cua:latest
    ```

  </Tab>
</Tabs>

</Step>

<Step>

## Install Cua

<Accordions type="single" defaultValue="uv">

<Accordion title="uv (Recommended)" value="uv">

### Install uv

<Tabs items={['macOS / Linux', 'Windows']} persist>
<Tab value="macOS / Linux">

```bash
# Use curl to download the script and execute it with sh:
curl -LsSf https://astral.sh/uv/install.sh | sh

# If your system doesn't have curl, you can use wget:
# wget -qO- https://astral.sh/uv/install.sh | sh
```

</Tab>
<Tab value="Windows">

```powershell
# Use irm to download the script and execute it with iex:
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"
```

</Tab>
</Tabs>

### Install Python 3.12

```bash
uv python install 3.12
# uv will install Cua dependencies automatically when you use --with "cua-agent[cli]"
```

</Accordion>

<Accordion title="conda" value="conda">

### Install conda

<Tabs items={['macOS', 'Linux', 'Windows']} persist>
<Tab value="macOS">

```bash
mkdir -p ~/miniconda3
curl https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh -o ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
source ~/miniconda3/bin/activate
```

</Tab>
<Tab value="Linux">

```bash
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm ~/miniconda3/miniconda.sh
source ~/miniconda3/bin/activate
```

</Tab>
<Tab value="Windows">

```powershell
wget "https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe" -outfile ".\miniconda.exe"
Start-Process -FilePath ".\miniconda.exe" -ArgumentList "/S" -Wait
del .\miniconda.exe
```

</Tab>
</Tabs>

### Create and activate Python 3.12 environment

```bash
conda create -n cua python=3.12
conda activate cua
```

### Install Cua

```bash
pip install "cua-agent[cli]" cua-computer
```

</Accordion>

<Accordion title="pip" value="pip">

### Install Cua

```bash
pip install "cua-agent[cli]" cua-computer
```

</Accordion>

</Accordions>

</Step>

<Step>

## Run Cua CLI

Choose your preferred AI model:

### OpenAI Computer Use Preview

<Tabs items={['uv', 'conda/pip']} persist>
<Tab value="uv">

```bash
uv run --with "cua-agent[cli]" -m agent.cli openai/computer-use-preview
```

</Tab>
<Tab value="conda/pip">

```bash
python -m agent.cli openai/computer-use-preview
```

</Tab>
</Tabs>

### Anthropic Claude

<Tabs items={['uv', 'conda/pip']} persist>
<Tab value="uv">

```bash
uv run --with "cua-agent[cli]" -m agent.cli anthropic/claude-sonnet-4-5-20250929
uv run --with "cua-agent[cli]" -m agent.cli anthropic/claude-opus-4-20250514
uv run --with "cua-agent[cli]" -m agent.cli anthropic/claude-opus-4-1-20250805
uv run --with "cua-agent[cli]" -m agent.cli anthropic/claude-sonnet-4-20250514
uv run --with "cua-agent[cli]" -m agent.cli anthropic/claude-3-5-sonnet-20241022
```

</Tab>
<Tab value="conda/pip">

```bash
python -m agent.cli anthropic/claude-sonnet-4-5-20250929
python -m agent.cli anthropic/claude-opus-4-1-20250805
python -m agent.cli anthropic/claude-opus-4-20250514
python -m agent.cli anthropic/claude-sonnet-4-20250514
python -m agent.cli anthropic/claude-3-5-sonnet-20241022
```

</Tab>
</Tabs>

### Omniparser + LLMs

<Tabs items={['uv', 'conda/pip']} persist>
<Tab value="uv">

```bash
uv run --with "cua-agent[cli]" -m agent.cli omniparser+anthropic/claude-3-5-sonnet-20241022
uv run --with "cua-agent[cli]" -m agent.cli omniparser+openai/gpt-4o
uv run --with "cua-agent[cli]" -m agent.cli omniparser+vertex_ai/gemini-pro
```

</Tab>
<Tab value="conda/pip">

```bash
python -m agent.cli omniparser+anthropic/claude-3-5-sonnet-20241022
python -m agent.cli omniparser+openai/gpt-4o
python -m agent.cli omniparser+vertex_ai/gemini-pro
```

</Tab>
</Tabs>

### Local Models

<Tabs items={['uv', 'conda/pip']} persist>
<Tab value="uv">

```bash
# Hugging Face models (local)
uv run --with "cua-agent[cli]" -m agent.cli huggingface-local/ByteDance-Seed/UI-TARS-1.5-7B

# MLX models (Apple Silicon)
uv run --with "cua-agent[cli]" -m agent.cli mlx/mlx-community/UI-TARS-1.5-7B-6bit

# Ollama models
uv run --with "cua-agent[cli]" -m agent.cli omniparser+ollama_chat/llama3.2:latest
```

</Tab>
<Tab value="conda/pip">

```bash
# Hugging Face models (local)
python -m agent.cli huggingface-local/ByteDance-Seed/UI-TARS-1.5-7B

# MLX models (Apple Silicon)
python -m agent.cli mlx/mlx-community/UI-TARS-1.5-7B-6bit

# Ollama models
python -m agent.cli omniparser+ollama_chat/llama3.2:latest
```

</Tab>
</Tabs>

### Interactive Setup

If you haven't set up environment variables, the CLI will guide you through the setup:

1. **Sandbox Name**: Enter your Cua sandbox name (or get one at [trycua.com](https://www.trycua.com/))
2. **CUA API Key**: Enter your Cua API key
3. **Provider API Key**: Enter your AI provider API key (OpenAI, Anthropic, etc.)

### Start Chatting

Once connected, you'll see:

```
ðŸ’» Connected to your-container-name (model, agent_loop)
Type 'exit' to quit.

>
```

You can ask your agent to perform actions like:

- "Take a screenshot and tell me what's on the screen"
- "Open Firefox and go to github.com"
- "Type 'Hello world' into the terminal"
- "Close the current window"
- "Click on the search button"

</Step>
</Steps>

---

For running models locally, see [Running Models Locally](/agent-sdk/supported-model-providers/local-models).
